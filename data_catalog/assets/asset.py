from csv import Sniffer
from io import StringIO, BytesIO
from typing import Union
from urllib.request import urlopen

import pandas as pd
from datetime import datetime
from azure.storage.blob import ContainerClient

from data_catalog.assets import Location
from data_catalog.client.asset import AssetResponse


class Asset(AssetResponse):
    """
    A service level class to extend the AssetResponse class generated by OpenAPI.
    It provides methods to obtain data from an Asset
    """

    def __init__(self, id=None, created_at=None, updated_at=None, name=None, description=None, location=None, tags=None,
                 format=None, size=None, namespace=None, local_vars_configuration=None):
        """
        Constructor of Asset
        :param str id:
        :param str created_at:
        :param str updated_at:
        :param str name:
        :param str description:
        :param Location location: The location where the asset data can be found
        :param list[str] tags: list of tags
        :param str format:
        :param str size:
        :param str namespace:
        :param local_vars_configuration:
        """

        super().__init__(id=id, created_at=created_at, updated_at=updated_at, name=name, description=description,
                         location=location, tags=tags, format=format, size=size, namespace=namespace,
                         local_vars_configuration=local_vars_configuration)

        if self.location is not None:
            self.location = Location(location.type, location.parameters)

    @staticmethod
    def from_response(asset_response: AssetResponse):
        """
        Converts an AssetResponse to a Response
        :param AssetResponse asset_response: Asset client generated with OpenAPI
        :return: asset
        :rtype: Asset
        """
        asset_response.__class__ = Asset
        return asset_response

    def get_data(self) -> Union[pd.DataFrame, ContainerClient]:
        """
        Obtains data from its location and returns it in a format specific to that location
        :return: if location type is 'url', then Pandas Data Frame,
                 if it  is 'azureblob', then ContainerClient
        :rtype: Union[pd.DataFrame, ContainerClient]
        """

        if self.location is None:
            raise ValueError('Asset location is not defined')

        # check location type
        if self.location.type == 'url':
            return self._get_data_from_url()
        elif self.location.type == 'azureblob':
            return self._get_data_from_container()
        else:
            raise NotImplementedError

    def _get_data_from_url(self) -> pd.DataFrame:
        """
        Obtains data when the location type is url
        :return: Pandas DataFrame
        :rtype: pd.DataFrame
        """
        url = self.location.get_parameter('url')
        if url is None:
            raise ValueError('Location has no url parameter')

        try:
            if self.format == 'csv':
                with urlopen(url) as f:
                    stream = BytesIO(f.read())

                stream.seek(0)
                delimiter = Sniffer().sniff(stream.read().decode()).delimiter

                stream.seek(0)
                data_frame = pd.read_csv(stream, sep=delimiter)
            elif self.format == 'json':
                data_frame = pd.read_json(url)
            else:
                raise NotImplementedError
        except pd.errors.ParserError:
            raise ValueError('Could not parse data from url')

        return data_frame

    def _get_data_from_container(self) -> pd.DataFrame:
        """
        Obtains data when the location type is azureblob (data from Azure Blob Storage)
        :return: pandas dataframe
        :rtype: pd.DataFrame
        """
        container = self._get_container()
        blob_list = container.list_blobs()
        data_frames = []
        try:
            if self.format == 'csv':
                for blob in blob_list:
                    stream = BytesIO()
                    container.download_blob(blob).readinto(stream)

                    stream.seek(0)
                    delimiter = Sniffer().sniff(stream.read().decode()).delimiter

                    stream.seek(0)
                    data_frames.append(pd.read_csv(stream, sep=delimiter))
            elif self.format == 'json':
                for blob in blob_list:
                    stream = BytesIO()
                    container.download_blob(blob).readinto(stream)

                    stream.seek(0)
                    data_frames.append(pd.read_json(stream))
            else:
                raise NotImplementedError
        except pd.errors.ParserError:
            raise ValueError('Could not parse the data from the blob container')

        return pd.concat(data_frames, ignore_index=True)

    def _get_container(self) -> ContainerClient:
        """

        :return:
        """
        account_url = self.location.get_parameter('accountUrl')
        container_name = self.location.get_parameter('containerName')
        credential = None

        if self.location.get_parameter('sasToken') is not None:
            expiry_time = datetime\
                .strptime(self.location.get_parameter('expiryTime'), '%Y-%m-%dT%H:%M:%SZ')

            if expiry_time >= datetime.now():
                credential = self.location.get_parameter('sasToken')

        if credential is None:
            credential = self.location.get_parameter('accountKey')

        if None in [account_url, container_name, credential]:
            raise ValueError('Parameters missing to create the container.')

        return ContainerClient(account_url=account_url,
                               container_name=container_name,
                               credential=credential)
